<!DOCTYPE html>
<html lang="en">
 <head>
  <meta charset="utf-8"/>
  <meta content="width=device-width, initial-scale=1.0" name="viewport"/>
  <meta content="Prawar Poudel" name="author"/>
  <meta content="Vector Databases, AI, Machine Learning, NLP, GPT" name="keywords"/>
  <meta content="" name="description"/>
  <link href="../css/main.css" rel="stylesheet" type="text/css"/>
  <title>
   Unsupervised Learning
  </title>
 </head>
 <body>
  <!-- this one is on the top for navigation -->
  <div class="navbar">
   <a href="../index.html">
    Home
   </a>
   <a href="../about.html">
    About
   </a>
   <a href="https://www.linkedin.com/in/prawarpoudel/">
    LinkedIn
   </a>
   <a href="https://scholar.google.com/citations?user=qa8tuSIAAAAJ&amp;hl=en">
    Google Scholar
   </a>
  </div>
  <!-- following is the sidebar -->
  <div class="sidebar">
   <a class="" href="https://prawarpoudel.github.io/about">
    About
   </a>
   <a class="listt" href="../pages/ai_topics.html">
    Various AI Topics
   </a>
   <a class="listt" href="../pages/datascience_topics.html">
    Various Data Science Topics
   </a>
   <a class="listt" href="../pages/programming_topics.html">
    Various Programming Topics
   </a>
   <a class="listt" href="../pages/reading_systemdesign.html">
    System Design Topics (Book)
   </a>
   <a class="listt" href="../pages/kube_topics.html">
    Various Kubernetes Topics
   </a>
   <a class="listt" href="../pages/coding_topics.html">
    Various Coding Examples
   </a>
   <a class="listt" href="../pages/ml_basics.html">
    Machine Learning Basics
   </a>
   <a class="listt" href="../pages/rag.html">
    RAG Concept
   </a>
   <a class="listt" href="../pages/rag_code.html">
    RAG Implementation
   </a>
   <a class="listt" href="../pages/redis_benchmarking.html">
    REDIS Benchmarking
   </a>
   <a class="listt" href="../pages/codellama.html">
    Code Llama Intro
   </a>
   <a class="listt" href="../pages/codellama_handson.html">
    Code Llama Hands-On
   </a>
   <a class="listt" href="../pages/breaking_codellama.html">
    Breaking Code Llama
   </a>
   <a class="listt" href="../pages/whyjohnnycantprompt.html">
    Why Jhonny Cant't Prompt
   </a>
   <a class="listt" href="../pages/discriminative.html">
    Discriminative Vs Generative Models
   </a>
   <a class="listt" href="../pages/gan.html">
    Generative Adversarial Models
   </a>
   <a class="listt" href="../pages/regex_py.html">
    Regex in python
   </a>
   <a class="listt" href="../pages/kube_health_checks.html">
    Kube Health Checks
   </a>
   <a class="listt" href="../pages/raft_consensus.html">
    Raft Algorithm (Consensus)
   </a>
   <a class="listt" href="../pages/alerting.html">
    Ex-Google SRE on Alerting
   </a>
   <a class="listt" href="../pages/primer_systemdesign.html">
    System Design Primer (Github)
   </a>
   <a class="listt" href="../pages/supervised_learning.html">
    Supervised Machine Learning
   </a>
   <a class="listt" href="../pages/unsupervised_learning_clustering.html">
    Unsupervised Machine Learning (Clustering)
   </a>
   <a class="listt" href="../pages/unsupervised_learning_dimsreduction.html">
    Unsupervised Machine Learning (Dimensn Redcsn)
   </a>
  </div>
  <div class="content">
   <h1>
    Unsupervised Learning
   </h1>
   <p>
    <ul>
     <li>
      Datapoints do not have any outcomes, or target is unknown.
     </li>
     <li>
      We are interested in the structure of the data or the patterns within the data.
     </li>
     <li>
      Types:
      <ul>
       <li>
        <a href="unsupervised_learning_clustering.html">
         <b>
          Clustering:
         </b>
        </a>
        Algorithm like:
        <ul>
         <li>
          K-Means
         </li>
         <li>
          Hierarchical Agglomerative Clustering
         </li>
         <li>
          DBSCAN
         </li>
         <li>
          Mean shift
         </li>
        </ul>
       </li>
       <li>
        <a href="unsupervised_learning_dimsreduction.html">
         <b>
          Dimensionality Reduction:
         </b>
        </a>
        Algorithm like:
        <ul>
         <li>
          PCA
         </li>
         <li>
          Non-negative matrix factorization
         </li>
         <li>
          They are important because of the
          <mark>
           curse of dimensionality
          </mark>
          .
         </li>
         <li>
          .. which means that as no of features increases performance gets worse, and cost or the number of training examples required increases.
         </li>
        </ul>
       </li>
      </ul>
     </li>
     <li>
      Many use cases like:
      <ul>
       <li>
        Classification
       </li>
       <li>
        Anomaly Detection
       </li>
       <li>
        Customer Segmentation
       </li>
       <li>
        Improve Supervised Learning
       </li>
      </ul>
     </li>
    </ul>
   </p>
   <hr/>
   <h2>
    Timeseries Analysis
   </h2>
   <p>
    <ul>
        <li>
            used for forecasting
        </li>
        <li>
            data correlated over time; and are often non-stationary. Thus, very hard to model.
        </li>
        <li>
            needs a lot of data
        </li>
        <li>
            propagation of forecast error from one period to another
        </li>
        <li>
            Time Series: sequence of data points that are organized in time. Data is equally spaced points in time. Irregular data is not considered Time Series.
        </li>
        <li>
            standard measures like <i>forecast miss</i> and <i>error rates by horizon</i> can be misleading
        </li>
        <li>
            <ul>
                <li>
                    <b>Univariate</b>: Single data series (could be continuous, binary or categorical); can be multiple unrelated or related series; could be conditional series
                </li>
                <li>
                    <b>Panel/Multivariate</b>: Multiple related series with identifying groups like customer types, department etc; may be used for joint estimation across series
                </li>
            </ul>
        </li>
        <li>
            some important functions for plotting are: plot_acf(), plot_pacf(), month_plot(), quarter_plot()
        </li>
    </ul>
   </p>
   <hr>
   <h4>Autocorrelation Plot</h4>
   <p>
    TODO
   </p>
   <p>
    <ul>
        <li>
            autocorrelation means todays data is highly dependent on some past value
        </li>
        <li>
            time interval between correlated values is called <mark>lag</mark>
        </li>
        <li>
            a simple way to remove autocorrelation in some degree is to perform subtraction with the lagged data, ie., <mark>data (t) = data_old(t) - data_old(t-delta)</mark>
        </li>
    </ul>
   </p>
   <hr>
   <h4>
    Decomposing Time series
   </h4>
   <p>
    <ul>
        <li>
            Decomposition allows to remove the deterministic components of data, and make modeling easier.
        </li>
        <li>
            Trend: Long Term direction, Seasonality: Periodic Behavior, Residual: Irregular/random Fluctuations that is left after trend or seasonality is removed.
        </li>
        <li>
            Models perform better if we remove known sources of variation. For example, trend and seasonality.
        </li>
        <li>
            Types of decomposition:
            <ul>
                <li>
                    Additive decomposition:
                </li>
                <li>
                    Multiplicative decomposition:
                </li>
                <li>
                    Pseudo-additive: combination of both above, for example, we expect a multplicative model, but there could be zero in the value.
                </li>
            </ul>
        </li>
        <li>
            How to decompose?
            <ul>
                <li>
                    Single, double or triple exponential smoothing
                </li>
                <li>
                    Locally Estimated Scatterplot Smoothing (LOESS)
                </li>
                <li>
                    Frequency based methods: uses spectral analysis
                </li>
            </ul>
        </li>
    </ul>
   </p>
   <p>
    in python use, <mark>from statsmodels.tsa.seasonal import seasonal_decompose</mark>. The output gives out all the three components, trend, seasonal and residuals. We can specify
    additive or multiplicative as the model to be used. The <mark>freq</mark> or the <mark>period</mark> argument is an important hyperparameter.
   </p>
   <p>
    <b>Stationarity</b>
    <ul>
        <li>
            Stationary data means having same mean and variance over time. 4 key properties of a stationary series are:
            <ul>
                <li>
                    constant mean
                </li>
                <li>
                    constant variance
                </li>
                <li>
                    constant autocorrelation structure
                </li>
                <li>
                    no periodic component
                </li>
            </ul>
        </li>
        <li>
            non-stationary models are very hard to model. Approach to handle non-stationary model is as follows:
            <ul>
                <li>
                    identify the source of non-stationary
                </li>
                <li>
                    transform series to make it stationary
                </li>
                <li>
                    build models with stationary series
                </li>
            </ul>
        </li>
        <li>
            <mark>Augmented-Dickey Fuller Test</mark> can be used to identify if a series is stationary or not. Other method is the visual method,to identify the 4 properties mentioned above.
        </li>
        <li>
            <p class="code-text">
from statsmodels.tsa.stattools import adfuller

adf,pvalue,usedlag,nobs,critical_value,icbest = adfuller(data)
            </p>
            <p>
                p-value too small means its not stationary. ADF value can sometimes be misleading in concluding the stationarity of the series. This is true in variance fluctuating series (heteroscadicity series)
            </p>
        </li>
        <li>

        </li>
    </ul>
   </p>
   </p>
  </div>
 </body>
</html>
